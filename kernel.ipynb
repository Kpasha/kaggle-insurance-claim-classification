{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting immediate approval of claims\n",
    "\n",
    "This project aims to build a predictive model that can predict the probability that a particular claim will be approved immediately or not by the insurance company.\n",
    "\n",
    "See the [README.md](https://github.com/cpatrickalves/kaggle-insurance-claim-classification) file and [competitions' page](https://www.kaggle.com/c/competicao-dsa-machine-learning-dec-2019/overview) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading useful Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "train_df = pd.read_csv('data/dataset_treino.csv')\n",
    "test_df = pd.read_csv('data/dataset_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1       NaN       NaN  C       NaN   9.191265       NaN       NaN   \n",
       "2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1       NaN       NaN  C       NaN        NaN       NaN       NaN   \n",
       "\n",
       "         v8  ...      v122      v123      v124  v125      v126      v127  \\\n",
       "0  0.012941  ...  8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n",
       "1  2.301630  ...       NaN       NaN  0.598896    AF       NaN       NaN   \n",
       "2  0.019645  ...  9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n",
       "3  0.171947  ...  7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n",
       "4       NaN  ...       NaN       NaN       NaN     Z       NaN       NaN   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0       NaN       NaN  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4       NaN     0       NaN       NaN  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "The first step before perform any kind of statistical analysis and modeling is to clean the data.\n",
    "\n",
    "Let's see the type of data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Columns: 133 entries, ID to v131\n",
      "dtypes: float64(108), int64(6), object(19)\n",
      "memory usage: 116.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that this data set has 114321 rows and 133 columns. \n",
    "\n",
    "Also, we have **114 numerical features** (columns) and **19 categorical features**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we have null values (also know as _NaN_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are null values?\n",
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v30       60110\n",
       "v113      55304\n",
       "v102      51316\n",
       "v85       50682\n",
       "v119      50680\n",
       "v51       50678\n",
       "v123      50678\n",
       "v23       50675\n",
       "v78       49895\n",
       "v115      49895\n",
       "v69       49895\n",
       "v131      49895\n",
       "v16       49895\n",
       "v122      49851\n",
       "v80       49851\n",
       "v9        49851\n",
       "v37       49843\n",
       "v118      49843\n",
       "v130      49843\n",
       "v19       49843\n",
       "v92       49843\n",
       "v95       49843\n",
       "v97       49843\n",
       "v20       49840\n",
       "v65       49840\n",
       "v121      49840\n",
       "v11       49836\n",
       "v39       49836\n",
       "v73       49836\n",
       "v90       49836\n",
       "          ...  \n",
       "v3         3457\n",
       "v31        3457\n",
       "v21         611\n",
       "v22         500\n",
       "v112        382\n",
       "v34         111\n",
       "v40         111\n",
       "v12          86\n",
       "v50          86\n",
       "v10          84\n",
       "v125         77\n",
       "v114         30\n",
       "v14           4\n",
       "v52           3\n",
       "v91           3\n",
       "v107          3\n",
       "v24           0\n",
       "v38           0\n",
       "v47           0\n",
       "v62           0\n",
       "v66           0\n",
       "v129          0\n",
       "v71           0\n",
       "v72           0\n",
       "v74           0\n",
       "v75           0\n",
       "v79           0\n",
       "v110          0\n",
       "target        0\n",
       "ID            0\n",
       "Length: 133, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values amount for each column\n",
    "train_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a lot of null values in several columns.\n",
    "\n",
    "Let's check the percentage of null values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v30       52.58\n",
       "v113      48.38\n",
       "v102      44.89\n",
       "v51       44.33\n",
       "v85       44.33\n",
       "v23       44.33\n",
       "v123      44.33\n",
       "v119      44.33\n",
       "v115      43.64\n",
       "v78       43.64\n",
       "v69       43.64\n",
       "v131      43.64\n",
       "v16       43.64\n",
       "v122      43.61\n",
       "v80       43.61\n",
       "v9        43.61\n",
       "v37       43.60\n",
       "v130      43.60\n",
       "v20       43.60\n",
       "v19       43.60\n",
       "v92       43.60\n",
       "v95       43.60\n",
       "v97       43.60\n",
       "v65       43.60\n",
       "v118      43.60\n",
       "v121      43.60\n",
       "v53       43.59\n",
       "v42       43.59\n",
       "v68       43.59\n",
       "v67       43.59\n",
       "          ...  \n",
       "v3         3.02\n",
       "v31        3.02\n",
       "v21        0.53\n",
       "v22        0.44\n",
       "v112       0.33\n",
       "v40        0.10\n",
       "v34        0.10\n",
       "v12        0.08\n",
       "v50        0.08\n",
       "v125       0.07\n",
       "v10        0.07\n",
       "v114       0.03\n",
       "v129       0.00\n",
       "target     0.00\n",
       "v107       0.00\n",
       "v14        0.00\n",
       "v24        0.00\n",
       "v38        0.00\n",
       "v47        0.00\n",
       "v52        0.00\n",
       "v62        0.00\n",
       "v66        0.00\n",
       "v71        0.00\n",
       "v72        0.00\n",
       "v74        0.00\n",
       "v75        0.00\n",
       "v79        0.00\n",
       "v91        0.00\n",
       "v110       0.00\n",
       "ID         0.00\n",
       "Length: 133, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = train_df.isnull().sum()\n",
    "null_values = round((null_values/train_df.shape[0] * 100), 2)\n",
    "null_values.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that we are dealing with anonymous data and we can't know the meaning of the data, I'll remove all columns with more than 40% of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 30 columns):\n",
      "target    114321 non-null int64\n",
      "v3        110864 non-null object\n",
      "v10       114237 non-null float64\n",
      "v12       114235 non-null float64\n",
      "v14       114317 non-null float64\n",
      "v21       113710 non-null float64\n",
      "v22       113821 non-null object\n",
      "v24       114321 non-null object\n",
      "v31       110864 non-null object\n",
      "v34       114210 non-null float64\n",
      "v38       114321 non-null int64\n",
      "v40       114210 non-null float64\n",
      "v47       114321 non-null object\n",
      "v50       114235 non-null float64\n",
      "v52       114318 non-null object\n",
      "v56       107439 non-null object\n",
      "v62       114321 non-null int64\n",
      "v66       114321 non-null object\n",
      "v71       114321 non-null object\n",
      "v72       114321 non-null int64\n",
      "v74       114321 non-null object\n",
      "v75       114321 non-null object\n",
      "v79       114321 non-null object\n",
      "v91       114318 non-null object\n",
      "v107      114318 non-null object\n",
      "v110      114321 non-null object\n",
      "v112      113939 non-null object\n",
      "v114      114291 non-null float64\n",
      "v125      114244 non-null object\n",
      "v129      114321 non-null int64\n",
      "dtypes: float64(8), int64(5), object(17)\n",
      "memory usage: 26.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the columns that have more than 40% of null values\n",
    "high_nan_rate_columns = null_values[null_values > 40].index\n",
    "\n",
    "# Make a copy if the original datasets and remove the columns\n",
    "train_df_cleaned = train_df.copy()\n",
    "test_df_cleaned = test_df.copy()\n",
    "train_df_cleaned.drop(high_nan_rate_columns, axis=1, inplace=True)\n",
    "test_df_cleaned.drop(high_nan_rate_columns, axis=1, inplace=True)\n",
    "\n",
    "# Remove the ID column (it is now useful for modeling)\n",
    "train_df_cleaned.drop(['ID'], axis=1, inplace=True)\n",
    "test_df_cleaned.drop(['ID'], axis=1, inplace=True)\n",
    "\n",
    "train_df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have only 30 columns in the data set.\n",
    "\n",
    "But we still have null values that need to be handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v56     6882\n",
       "v31     3457\n",
       "v3      3457\n",
       "v21      611\n",
       "v22      500\n",
       "v112     382\n",
       "v40      111\n",
       "v34      111\n",
       "v50       86\n",
       "v12       86\n",
       "v10       84\n",
       "v125      77\n",
       "v114      30\n",
       "v14        4\n",
       "v91        3\n",
       "v107       3\n",
       "v52        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values_columns = train_df_cleaned.isnull().sum().sort_values(ascending=False)\n",
    "null_values_columns = null_values_columns[null_values_columns > 0]\n",
    "null_values_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 17 columns):\n",
      "v56     107439 non-null object\n",
      "v31     110864 non-null object\n",
      "v3      110864 non-null object\n",
      "v21     113710 non-null float64\n",
      "v22     113821 non-null object\n",
      "v112    113939 non-null object\n",
      "v40     114210 non-null float64\n",
      "v34     114210 non-null float64\n",
      "v50     114235 non-null float64\n",
      "v12     114235 non-null float64\n",
      "v10     114237 non-null float64\n",
      "v125    114244 non-null object\n",
      "v114    114291 non-null float64\n",
      "v14     114317 non-null float64\n",
      "v91     114318 non-null object\n",
      "v107    114318 non-null object\n",
      "v52     114318 non-null object\n",
      "dtypes: float64(8), object(9)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_cleaned[null_values_columns.index].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, there are 8 numeric columns and 9 categorical columns with nulls values.\n",
    "\n",
    "For now, we will replace the null values by the MEAN value for each numeric column and for the MODE for each of the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Numerical columns\n",
    "numerical_col_null_values = train_df_cleaned[null_values_columns.index].select_dtypes(include=['float64']).columns\n",
    "# for each column\n",
    "for c in numerical_col_null_values:\n",
    "    # Get the mean\n",
    "    mean = train_df_cleaned[c].mean()\n",
    "    # replace the NaN by mode\n",
    "    train_df_cleaned[c].fillna(mean, inplace=True)\n",
    "\n",
    "##### Categorical columns\n",
    "categ_col_null_values = train_df_cleaned[null_values_columns.index].select_dtypes(include=['object']).columns\n",
    "# for each column\n",
    "for c in categ_col_null_values:\n",
    "    # Get the most frequent value (mode)\n",
    "    mode = train_df_cleaned[c].value_counts().index[0]\n",
    "    # replace the NaN by mode\n",
    "    train_df_cleaned[c].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are null values?\n",
    "train_df_cleaned.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
